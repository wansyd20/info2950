{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c57c82e5",
   "metadata": {},
   "source": [
    "Research Questions Notes: \n",
    "would we have enough vine results? compare against vine reulsts, scale against unhelpful, not helpful, fake\n",
    "would also have to come up with why vine vs nonvine is an important research question\n",
    "\n",
    "Readme File:\n",
    "create a readme, don't submit all the separate files to CMS just to github and creat a readme about what is happening\n",
    "very tough to look for fake reviews, is there or is there not fake reviews??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f57e5b",
   "metadata": {},
   "source": [
    "Meeting with Professor:\n",
    " - project could lean heavily towards text analysis\n",
    "     - major challenge would be --> how do i turn this block of text into numerical features? \n",
    "         - start by counting individual distinct words\n",
    "     - just looking at factors (e.g. verified purchase, length of review, prescense/absence of title) will be enough for phase 2\n",
    "     - if struggling --> have a conversation w/ professor again about implementing text analysis\n",
    "         - **professor could give us a different dataset and compare two different review datasets to see rating pracgices between different online communities, why are there distinctive differences, predict rating of product on another marketplace that has diff marketplace standard**\n",
    " - looking for relationships between data, how we can build a model to proedict other target vairables of interest, \n",
    " - research question: \n",
    "     - finding fake reviews\n",
    "     - (as first step, exploratory analysis) characterizing different product categories by distribution of review ratings, types\n",
    "     \n",
    "using vine reviews as a gold standard while subsetting 10,000 reviews, we create can two distinct datasets two prevent loss of vine reviews:\n",
    " - take all the vine reviews (careful not to amplify by making sure to distinguish it as a vine review) \n",
    " - second dataset of non vine reviews that is randomly sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56047588",
   "metadata": {},
   "source": [
    "# Research Question\n",
    "1. How do consumer review behaviors including star ratings, text attributes of reviews, customer review frequency, helpful votes, verified purchases, etc. vary across different US online retailer sites (Amazon vs Walmart)? Are there any consistent differences between retailer sites and why/which types of products might they be occuring? \n",
    "2. Predict ratings/behavior based on retailer website? Is any one site more reliable than another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1238ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313344a",
   "metadata": {},
   "source": [
    "# Data Collection and Cleaning of Amazon Review Datasets\n",
    "We are using the Beauty category to demonstrate how we loaded and narrowed down the review dataset process. We performed the same processes to three other Amazon review categories (Electronics, Office Products, Apparel) in separate JupyterNotebook files. We loaded those cleaned versions here and merged all the cleaned datasets into one comprehensive dataset, which we have provided in CMS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a3955fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 10093: expected 15 fields, saw 22\\nSkipping line 31965: expected 15 fields, saw 22\\nSkipping line 49886: expected 15 fields, saw 22\\nSkipping line 49905: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 67579: expected 15 fields, saw 22\\nSkipping line 75367: expected 15 fields, saw 22\\nSkipping line 92462: expected 15 fields, saw 22\\nSkipping line 105041: expected 15 fields, saw 22\\nSkipping line 109697: expected 15 fields, saw 22\\nSkipping line 121931: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 139492: expected 15 fields, saw 22\\nSkipping line 158729: expected 15 fields, saw 22\\nSkipping line 165784: expected 15 fields, saw 22\\nSkipping line 176996: expected 15 fields, saw 22\\nSkipping line 182928: expected 15 fields, saw 22\\nSkipping line 195841: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 196938: expected 15 fields, saw 22\\nSkipping line 202535: expected 15 fields, saw 22\\nSkipping line 261147: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 265777: expected 15 fields, saw 22\\nSkipping line 277693: expected 15 fields, saw 22\\nSkipping line 280010: expected 15 fields, saw 22\\nSkipping line 296315: expected 15 fields, saw 22\\nSkipping line 299043: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 334564: expected 15 fields, saw 22\\nSkipping line 337801: expected 15 fields, saw 22\\nSkipping line 341391: expected 15 fields, saw 22\\nSkipping line 354940: expected 15 fields, saw 22\\nSkipping line 366330: expected 15 fields, saw 22\\nSkipping line 367649: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 399174: expected 15 fields, saw 22\\nSkipping line 414439: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 473579: expected 15 fields, saw 22\\nSkipping line 483540: expected 15 fields, saw 22\\nSkipping line 499744: expected 15 fields, saw 22\\nSkipping line 505775: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 547693: expected 15 fields, saw 22\\nSkipping line 561254: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 609329: expected 15 fields, saw 22\\nSkipping line 642814: expected 15 fields, saw 22\\nSkipping line 643189: expected 15 fields, saw 22\\nSkipping line 647075: expected 15 fields, saw 22\\nSkipping line 647457: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 660868: expected 15 fields, saw 22\\nSkipping line 668514: expected 15 fields, saw 22\\nSkipping line 673314: expected 15 fields, saw 22\\nSkipping line 700416: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 723492: expected 15 fields, saw 22\\nSkipping line 725052: expected 15 fields, saw 22\\nSkipping line 726222: expected 15 fields, saw 22\\nSkipping line 744078: expected 15 fields, saw 22\\nSkipping line 753129: expected 15 fields, saw 22\\nSkipping line 758347: expected 15 fields, saw 22\\nSkipping line 759076: expected 15 fields, saw 22\\nSkipping line 759139: expected 15 fields, saw 22\\nSkipping line 768106: expected 15 fields, saw 22\\nSkipping line 777835: expected 15 fields, saw 22\\nSkipping line 779763: expected 15 fields, saw 22\\nSkipping line 781395: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 787023: expected 15 fields, saw 22\\nSkipping line 811679: expected 15 fields, saw 22\\nSkipping line 811739: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 855784: expected 15 fields, saw 22\\nSkipping line 878325: expected 15 fields, saw 22\\nSkipping line 886822: expected 15 fields, saw 22\\nSkipping line 890742: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 919607: expected 15 fields, saw 22\\nSkipping line 920655: expected 15 fields, saw 22\\nSkipping line 923107: expected 15 fields, saw 22\\nSkipping line 930890: expected 15 fields, saw 22\\nSkipping line 932841: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1003214: expected 15 fields, saw 22\\nSkipping line 1007588: expected 15 fields, saw 22\\nSkipping line 1018374: expected 15 fields, saw 22\\nSkipping line 1022909: expected 15 fields, saw 22\\nSkipping line 1030983: expected 15 fields, saw 22\\nSkipping line 1048441: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1056292: expected 15 fields, saw 22\\nSkipping line 1056518: expected 15 fields, saw 22\\nSkipping line 1073064: expected 15 fields, saw 22\\nSkipping line 1088887: expected 15 fields, saw 22\\nSkipping line 1103881: expected 15 fields, saw 22\\nSkipping line 1111021: expected 15 fields, saw 22\\nSkipping line 1111314: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1119421: expected 15 fields, saw 22\\nSkipping line 1119549: expected 15 fields, saw 22\\nSkipping line 1130122: expected 15 fields, saw 22\\nSkipping line 1132767: expected 15 fields, saw 22\\nSkipping line 1143315: expected 15 fields, saw 22\\nSkipping line 1151947: expected 15 fields, saw 22\\nSkipping line 1154207: expected 15 fields, saw 22\\nSkipping line 1154616: expected 15 fields, saw 22\\nSkipping line 1155875: expected 15 fields, saw 22\\nSkipping line 1164714: expected 15 fields, saw 22\\nSkipping line 1164959: expected 15 fields, saw 22\\nSkipping line 1169410: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1184604: expected 15 fields, saw 22\\nSkipping line 1203964: expected 15 fields, saw 22\\nSkipping line 1211287: expected 15 fields, saw 22\\nSkipping line 1217834: expected 15 fields, saw 22\\nSkipping line 1235346: expected 15 fields, saw 22\\nSkipping line 1238073: expected 15 fields, saw 22\\nSkipping line 1238439: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1246837: expected 15 fields, saw 22\\nSkipping line 1263235: expected 15 fields, saw 22\\nSkipping line 1265620: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1312400: expected 15 fields, saw 22\\nSkipping line 1314122: expected 15 fields, saw 22\\nSkipping line 1319707: expected 15 fields, saw 22\\nSkipping line 1337672: expected 15 fields, saw 22\\nSkipping line 1343961: expected 15 fields, saw 22\\nSkipping line 1346372: expected 15 fields, saw 22\\nSkipping line 1358447: expected 15 fields, saw 22\\nSkipping line 1370844: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1406108: expected 15 fields, saw 22\\nSkipping line 1435069: expected 15 fields, saw 22\\nSkipping line 1439866: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1442123: expected 15 fields, saw 22\\nSkipping line 1463237: expected 15 fields, saw 22\\nSkipping line 1469027: expected 15 fields, saw 22\\nSkipping line 1469598: expected 15 fields, saw 22\\nSkipping line 1482636: expected 15 fields, saw 22\\nSkipping line 1484745: expected 15 fields, saw 22\\nSkipping line 1499831: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1508882: expected 15 fields, saw 22\\nSkipping line 1514887: expected 15 fields, saw 22\\nSkipping line 1527564: expected 15 fields, saw 22\\nSkipping line 1569519: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1583105: expected 15 fields, saw 22\\nSkipping line 1604380: expected 15 fields, saw 22\\nSkipping line 1607380: expected 15 fields, saw 22\\nSkipping line 1631601: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1642095: expected 15 fields, saw 22\\nSkipping line 1646714: expected 15 fields, saw 22\\nSkipping line 1655248: expected 15 fields, saw 22\\nSkipping line 1657807: expected 15 fields, saw 22\\nSkipping line 1667534: expected 15 fields, saw 22\\nSkipping line 1668489: expected 15 fields, saw 22\\nSkipping line 1691733: expected 15 fields, saw 22\\nSkipping line 1701102: expected 15 fields, saw 22\\nSkipping line 1701499: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1704450: expected 15 fields, saw 22\\nSkipping line 1706154: expected 15 fields, saw 22\\nSkipping line 1712789: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1773984: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1846441: expected 15 fields, saw 22\\nSkipping line 1848019: expected 15 fields, saw 22\\nSkipping line 1856015: expected 15 fields, saw 22\\nSkipping line 1858248: expected 15 fields, saw 22\\nSkipping line 1859629: expected 15 fields, saw 22\\nSkipping line 1873117: expected 15 fields, saw 22\\nSkipping line 1894414: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1902421: expected 15 fields, saw 22\\nSkipping line 1909201: expected 15 fields, saw 22\\nSkipping line 1914394: expected 15 fields, saw 22\\nSkipping line 1936976: expected 15 fields, saw 22\\nSkipping line 1940327: expected 15 fields, saw 22\\nSkipping line 1945664: expected 15 fields, saw 22\\nSkipping line 1946171: expected 15 fields, saw 22\\nSkipping line 1946284: expected 15 fields, saw 22\\nSkipping line 1946835: expected 15 fields, saw 22\\nSkipping line 1952446: expected 15 fields, saw 22\\nSkipping line 1953387: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1979093: expected 15 fields, saw 22\\nSkipping line 1982997: expected 15 fields, saw 22\\nSkipping line 1992924: expected 15 fields, saw 22\\nSkipping line 1996161: expected 15 fields, saw 22\\nSkipping line 2003175: expected 15 fields, saw 22\\nSkipping line 2024153: expected 15 fields, saw 22\\nSkipping line 2026345: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2041159: expected 15 fields, saw 22\\nSkipping line 2042954: expected 15 fields, saw 22\\nSkipping line 2044244: expected 15 fields, saw 22\\nSkipping line 2047949: expected 15 fields, saw 22\\nSkipping line 2051022: expected 15 fields, saw 22\\nSkipping line 2052365: expected 15 fields, saw 22\\nSkipping line 2064460: expected 15 fields, saw 22\\nSkipping line 2077010: expected 15 fields, saw 22\\nSkipping line 2083893: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2097514: expected 15 fields, saw 22\\nSkipping line 2100479: expected 15 fields, saw 22\\nSkipping line 2103183: expected 15 fields, saw 22\\nSkipping line 2108608: expected 15 fields, saw 22\\nSkipping line 2116577: expected 15 fields, saw 22\\nSkipping line 2127375: expected 15 fields, saw 22\\nSkipping line 2128053: expected 15 fields, saw 22\\nSkipping line 2135954: expected 15 fields, saw 22\\nSkipping line 2137154: expected 15 fields, saw 22\\nSkipping line 2140279: expected 15 fields, saw 22\\nSkipping line 2150764: expected 15 fields, saw 22\\nSkipping line 2151464: expected 15 fields, saw 22\\nSkipping line 2151588: expected 15 fields, saw 22\\nSkipping line 2157049: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2163762: expected 15 fields, saw 22\\nSkipping line 2167939: expected 15 fields, saw 22\\nSkipping line 2172050: expected 15 fields, saw 22\\nSkipping line 2177960: expected 15 fields, saw 22\\nSkipping line 2202813: expected 15 fields, saw 22\\nSkipping line 2207828: expected 15 fields, saw 22\\nSkipping line 2211189: expected 15 fields, saw 22\\nSkipping line 2211589: expected 15 fields, saw 22\\nSkipping line 2214034: expected 15 fields, saw 22\\nSkipping line 2214264: expected 15 fields, saw 22\\nSkipping line 2214462: expected 15 fields, saw 22\\nSkipping line 2215027: expected 15 fields, saw 22\\nSkipping line 2215639: expected 15 fields, saw 22\\nSkipping line 2216007: expected 15 fields, saw 22\\nSkipping line 2217132: expected 15 fields, saw 22\\nSkipping line 2226703: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2231683: expected 15 fields, saw 22\\nSkipping line 2245222: expected 15 fields, saw 22\\nSkipping line 2256136: expected 15 fields, saw 22\\nSkipping line 2269399: expected 15 fields, saw 22\\nSkipping line 2283979: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2340899: expected 15 fields, saw 22\\nSkipping line 2342134: expected 15 fields, saw 22\\nSkipping line 2342748: expected 15 fields, saw 22\\nSkipping line 2348402: expected 15 fields, saw 22\\nSkipping line 2355164: expected 15 fields, saw 22\\nSkipping line 2357020: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2366077: expected 15 fields, saw 22\\nSkipping line 2366997: expected 15 fields, saw 22\\nSkipping line 2367353: expected 15 fields, saw 22\\nSkipping line 2414691: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2464571: expected 15 fields, saw 22\\nSkipping line 2466302: expected 15 fields, saw 22\\nSkipping line 2487679: expected 15 fields, saw 22\\nSkipping line 2487771: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2506605: expected 15 fields, saw 22\\nSkipping line 2511369: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2558281: expected 15 fields, saw 22\\nSkipping line 2607202: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2625718: expected 15 fields, saw 22\\nSkipping line 2640978: expected 15 fields, saw 22\\nSkipping line 2650635: expected 15 fields, saw 22\\nSkipping line 2670724: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2690954: expected 15 fields, saw 22\\nSkipping line 2713810: expected 15 fields, saw 22\\nSkipping line 2715292: expected 15 fields, saw 22\\nSkipping line 2724453: expected 15 fields, saw 22\\nSkipping line 2724458: expected 15 fields, saw 22\\nSkipping line 2735678: expected 15 fields, saw 22\\nSkipping line 2740358: expected 15 fields, saw 22\\nSkipping line 2751188: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2763890: expected 15 fields, saw 22\\nSkipping line 2766982: expected 15 fields, saw 22\\nSkipping line 2813747: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2819306: expected 15 fields, saw 22\\nSkipping line 2883075: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2975635: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3391761: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3474241: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3690054: expected 15 fields, saw 22\\nSkipping line 3720113: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3763182: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4929700: expected 15 fields, saw 22\\n'\n",
      "/Users/michellehui/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "beauty_raw = pd.read_csv('/Users/michellehui/info2950_project/amazon_reviews_us_Beauty_v1_00.tsv', sep = '\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3de767",
   "metadata": {},
   "outputs": [],
   "source": [
    "beauty_raw.to_csv('amazonreviews_beauty_raw.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9623ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "beauty = pd.read_csv('amazonreviews_beauty_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfb848",
   "metadata": {},
   "source": [
    "Here we converted the review date to datetime type. When then kept only the reviews written in 2015, which is the most recent year in the dataset. We did this to narrow down the millions of reviews to a more manageable size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f35513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping reviews written in 2015\n",
    "beauty['review_date'] = pd.to_datetime(beauty['review_date'])\n",
    "beauty = beauty.loc[beauty['review_date'].dt.year == 2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f0edb8",
   "metadata": {},
   "source": [
    "In order to narrow the dataset down to a more reasonable size as there are still around 500,000-1,000,000 reviews per product category from 2015, we are randomly selecting 10,000 observations from each category. We then reset the index on each dataset to be from 0-9,999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918f9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly narrowing down 800,000 observations to 10,000\n",
    "beauty = beauty.sample(n=10000).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed11a47e",
   "metadata": {},
   "source": [
    "Here we are dropping the unecessary columns. (1) We first dropped the Marketplace column because all the products were sold in the US. (2) We also dropped the index column as we reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cd6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping marketplace and index column\n",
    "beauty = beauty.drop(columns= ['marketplace', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading cleaned csv file\n",
    "beauty.to_csv('amazonreviews_beauty.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043b3e5",
   "metadata": {},
   "source": [
    "We repeated the above data cleaning process on three other amazon review datasets including the electronics, apparel, and office products. We are now loading these files onto this document and merging them into one dataset in order to perform exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bba2da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing cleaned amazon review datasets\n",
    "electronics_clean = pd.read_csv('amazonreviews_electronics.csv')\n",
    "beauty_clean = pd.read_csv('amazonreviews_beauty.csv')\n",
    "apparel_clean = pd.read_csv('amazonreviews_apparel.csv')\n",
    "office_products_clean = pd.read_csv('amazonreviews_office_products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c7f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating datasets\n",
    "amazon_reviews = pd.concat([electronics_clean, beauty_clean, apparel_clean, office_products_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8458e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing product_parent column\n",
    "amazon_reviews = amazon_reviews.drop(columns= ['product_parent', 'total_votes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53872dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading concatendated dataset\n",
    "amazon_reviews.to_csv('amazon_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7411b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in Amazon Reviews\n",
    "amazon_reviews = pd.read_csv('amazon_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b86ab96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20629638</td>\n",
       "      <td>R28COXZFGZBCD7</td>\n",
       "      <td>B00TF9UDZ4</td>\n",
       "      <td>[New Upgraded Version] MEMTEQ® Waterproof Blue...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Arrived dead. Charged it all night and it stil...</td>\n",
       "      <td>Arrived dead.  Charged it all night and it sti...</td>\n",
       "      <td>2015-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22433142</td>\n",
       "      <td>R3JWQ7N8ZTBE87</td>\n",
       "      <td>B00M4LBO12</td>\n",
       "      <td>JVC HAS200V RIPTIDZ Portable On-Ear Headband H...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Great sound</td>\n",
       "      <td>Sound was loud compared to previous headset. I...</td>\n",
       "      <td>2015-06-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46722229</td>\n",
       "      <td>RA1FWXIPF7Y3V</td>\n",
       "      <td>B00OHHG768</td>\n",
       "      <td>C&amp;E Mini HDMI 3-In 1-Out (Hdmi V1.3) Intellige...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Handy device for older TV's or single HDMI por...</td>\n",
       "      <td>Works as expected. Plug in any device and use ...</td>\n",
       "      <td>2015-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45124887</td>\n",
       "      <td>R3NERI9H0KG3MY</td>\n",
       "      <td>B005YHC4LW</td>\n",
       "      <td>Lepai LP-808 Stereo Amplifer built with LA4636...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>It's good get the job done.....</td>\n",
       "      <td>2015-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32907802</td>\n",
       "      <td>R1P6JH0BI5A0BW</td>\n",
       "      <td>B00VW7U8X4</td>\n",
       "      <td>Bose QuietComfort 25 Headphones (wired, 3.5mm)</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>indispensable for frequent flyers</td>\n",
       "      <td>I've had what I believe to be the precious mod...</td>\n",
       "      <td>2015-06-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id       review_id  product_id  \\\n",
       "0     20629638  R28COXZFGZBCD7  B00TF9UDZ4   \n",
       "1     22433142  R3JWQ7N8ZTBE87  B00M4LBO12   \n",
       "2     46722229   RA1FWXIPF7Y3V  B00OHHG768   \n",
       "3     45124887  R3NERI9H0KG3MY  B005YHC4LW   \n",
       "4     32907802  R1P6JH0BI5A0BW  B00VW7U8X4   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  [New Upgraded Version] MEMTEQ® Waterproof Blue...      Electronics   \n",
       "1  JVC HAS200V RIPTIDZ Portable On-Ear Headband H...      Electronics   \n",
       "2  C&E Mini HDMI 3-In 1-Out (Hdmi V1.3) Intellige...      Electronics   \n",
       "3  Lepai LP-808 Stereo Amplifer built with LA4636...      Electronics   \n",
       "4     Bose QuietComfort 25 Headphones (wired, 3.5mm)      Electronics   \n",
       "\n",
       "   star_rating  helpful_votes vine verified_purchase  \\\n",
       "0          1.0            0.0    N                 Y   \n",
       "1          5.0            0.0    N                 N   \n",
       "2          4.0            0.0    N                 Y   \n",
       "3          4.0            0.0    N                 Y   \n",
       "4          5.0            2.0    Y                 N   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0  Arrived dead. Charged it all night and it stil...   \n",
       "1                                        Great sound   \n",
       "2  Handy device for older TV's or single HDMI por...   \n",
       "3                                         Four Stars   \n",
       "4                  indispensable for frequent flyers   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  Arrived dead.  Charged it all night and it sti...  2015-06-24  \n",
       "1  Sound was loud compared to previous headset. I...  2015-06-21  \n",
       "2  Works as expected. Plug in any device and use ...  2015-05-08  \n",
       "3                    It's good get the job done.....  2015-08-04  \n",
       "4  I've had what I believe to be the precious mod...  2015-06-22  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8db565",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "## Motivation\n",
    " - **Why was this dataset created?**\n",
    "     - This dataset was intended to facilitate public study into the properties of Amazon customer reviews including how consumers evolve, express, and evaluate Amazon products.\n",
    " \n",
    " - **Who funded the creation of the dataset?**\n",
    "     - Amazon funded and collected this Amazon Customer Reviews Product for public use. The information is publicly available on Amazon Web Services.\n",
    "\n",
    "## Composition\n",
    "  - **What are the observations (rows) and the attributes (columns)?**\n",
    "      - The observations consist of each individual review. Each review has the following column attributes: customer_id, review_id, product_id, product_title, product_category (Beauty, Electronics, Office Products, Apparel), star_rating (Scale of 1-5), helpful_votes, vine (Amazon invites select credible users to review products through their Vine program), verified_purchase, review_headline, review_body, and review_date.\n",
    "  \n",
    " - **How many instances are there in the dataset? Does it contain all possible instances or is it a sample? What processes might have influenced what data was observed and recorded and what was not?**\n",
    "     - There are a total of 40,000 observations. This is split into 10,000 observations per product category. The original dataset with over a million reviews per product category is a sample collected by Amazon. Amazon constructed this dataset hoping to represent a sample of different customer opinions and demographics. We then narrowed the dataset even further by most recent year and then by random selection to our current size of 10,000 reviews per product category. \n",
    " \n",
    " - **Where can your raw source data be found, if applicable? Provide a link to the raw data (hosted in a Cornell Google Drive or Cornell Box).**\n",
    "     - The raw source can be found on Amazon Web Services. Here is the link to raw datasets also uploaded on google drive: https://drive.google.com/drive/folders/1F1Z1ERhp18uaB9J1d-dkGYhBCbJnPyXC?usp=sharing\n",
    " \n",
    " - **Is the data self contained or does it rely on other outside websites?**\n",
    "     - The data is self-contained in a downloaded tsv file.\n",
    " \n",
    " - **Does this data relate to individuals? Can the individuals be identified? Are there any subpopulations that can be identified?**\n",
    "     - Each individual review is associated to a reviewer through customer_id. However, there is no further information about this individual and customers cannot be split off into smaller subpopulations.\n",
    " \n",
    "## Collection Process\n",
    " - **If people are involved, were they aware of the data collection and if so, what purpose did they expect the data to be used for?**\n",
    "     - The reviewers in the dataset are not aware of their reviews being used for this purpose. They gave their consent to Amazon when they published their reviews publicly on Amazon. \n",
    " \n",
    " - **What time frame was the data collected?**\n",
    "     - Amazon collected reviews starting from 1995 all the way to 2015. \n",
    " \n",
    "## Preprocessing\n",
    " - **What preprocessing was done, and how did the data come to be in the form that you are using?**\n",
    "     - Refer to data cleaning appendix. \n",
    " \n",
    "  - **Are there are any errors, sources of noise, or redundancies in the data?**\n",
    "      - There were some observations with additional attributes/columns when parsing in the data from a csv file. We handled this by skipping over these lines and not including in the final dataset as it would not be reasonable to comb through the millions of reviews to individually handle each of these errors.\n",
    " \n",
    "## Uses\n",
    " - **Has this data been used before? If so, what for?**\n",
    "     - There are no public publishings using this dataset that could be found. However, we found a few other Amazon review analysis using other Amazon datasets. These analyses consisted mainly of review sentiment analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd83e3f",
   "metadata": {},
   "source": [
    "# Data Limitations\n",
    " - It could be difficult to compare the exact two products/brands between retailers as both retailers might not sell the same products.\n",
    " - While Amazon has the vine program to confirm credible reviews, Walmart does not have the same program. \n",
    " - The Walmart dataset also does not have a detailed breakdown of product categories that Amazon has. \n",
    " - It could be difficult to analyze the review text content as it requires in-depth natural language processing, which is beyond the scope of what we will learn in this course. \n",
    " - The Walmart dataset that we were able to acquire is a free sample that is not as comprehensive as the Amazon review dataset. There are a differing amount of reviews collected from each site.\n",
    " - By selecting only 10,000 reviews out of each product category, we also risk losing a lot of important observations such as vine reviews, reviews that are voted highly helpful, and various reviews across products/categories made by the same customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71589841",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    " ## Amazon\n",
    " Sydney:\n",
    " - histogram of star ratings by product category vs overall distribution\n",
    "     - summary statistics: mean, median, standard deviation\n",
    " - historgram of review length by product category vs overall distribution\n",
    "     - summary statistics\n",
    " - correlation between review length and star ratings\n",
    "     - correlation coefficients\n",
    " - look at unique products/brand and see if there are multiple reviews for the same product\n",
    "     - select most popular reviews and could potentially exclusively compare these products against Walmart\n",
    "     \n",
    " Michelle:    \n",
    " - bar chart (bins of helpful votes) to see distribution of helpful votes\n",
    " - percentage of verified purchases, vine reviews by product category\n",
    "     - correlation between verified purchases and helpful votes\n",
    "     - correlation between vine and helpful votes\n",
    " - reviewers who have written multiple reviews?\n",
    "\n",
    "\n",
    "## Walmart\n",
    "\n",
    "## Amazon vs Walmart\n",
    " - frequency of words in review text on Amazon vs Walmart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff5691",
   "metadata": {},
   "source": [
    "# Question for Reviewers\n",
    "1. Are we able to make predictions from observed differences in trends between Walmart and Amazon? If so, what types of predictions will we be able to reliably make?\n",
    "2. Are there any other research areas that we can explore?\n",
    "3. Should we attempt to conduct natural language processing/sentiment analysis on the review text? Will that be beyond our capabilities as introductory students.\n",
    "4. Should we expand/narrow down on certain products/categories/retail sites to get a more in-depth overview of consumer review trends?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
